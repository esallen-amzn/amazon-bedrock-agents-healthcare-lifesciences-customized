from .utils import get_ssm_parameter
from .memory_hook_provider import MemoryHook
from .config_manager import get_config_manager, ConfigManager, DiagnosisConfig
from mcp.client.streamable_http import streamablehttp_client
from strands import Agent
from strands_tools import current_time, retrieve
from strands.models import BedrockModel
from strands.tools.mcp import MCPClient
from typing import List, Optional
import logging

# Import local tools
try:
    from .tools.diagnosis_tools import generate_diagnosis, calculate_confidence_score, generate_recommendations
    from .tools.log_analysis_tools import analyze_logs, process_large_files, extract_failure_indicators
    from .tools.component_recognition_tools import extract_components, map_functions, build_inventory, resolve_naming, correlate_components, search_components
    LOCAL_TOOLS_AVAILABLE = True
except ImportError as e:
    # Logger might not be defined yet, so use print for now
    print(f"Local tools not available: {e}")
    LOCAL_TOOLS_AVAILABLE = False

logger = logging.getLogger(__name__)


class InstrumentDiagnosisAgent:
    """
    Instrument Diagnosis Assistant Agent
    
    AI agent specialized in analyzing instrument logs, recognizing system components,
    and providing troubleshooting guidance using Amazon Nova models.
    """
    
    def __init__(
        self,
        bearer_token: str,
        memory_hook: MemoryHook,
        config_manager: Optional[ConfigManager] = None,
        tools: List[callable] = None,
    ):
        # Initialize configuration manager with fallback
        try:
            self.config_manager = config_manager or get_config_manager()
            self.config = self.config_manager.get_config()
            
            # Set up model configuration
            model_config = self.config.models
            self.model_id = model_config.text_model
            self.multimodal_model_id = model_config.multimodal_model
            temperature = model_config.temperature
            top_p = model_config.top_p
            max_tokens = model_config.max_tokens
        except Exception as e:
            logger.warning(f"Configuration error, using defaults: {e}")
            # Use default values if config fails
            self.model_id = "us.amazon.nova-pro-v1:0"
            self.multimodal_model_id = "us.amazon.nova-canvas-v1:0"
            temperature = 0.3
            top_p = 0.9
            max_tokens = 4096
        
        # Create primary model for text analysis
        self.model = BedrockModel(
            model_id=self.model_id,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens,
        )
        
        # Create multimodal model for document processing
        self.multimodal_model = BedrockModel(
            model_id=self.multimodal_model_id,
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens,
        )
        
        # Set up system prompt for instrument diagnosis
        self.system_prompt = self._get_system_prompt()
        
        logger.info(f"Initialized Instrument Diagnosis Agent with models: {self.model_id}, {self.multimodal_model_id}")

        # Initialize gateway client (optional)
        self.gateway_client = None
        gateway_tools = []
        
        try:
            gateway_url = get_ssm_parameter("/app/myapp/agentcore/gateway_url")
            logger.info(f"Gateway Endpoint - MCP URL: {gateway_url}")

            self.gateway_client = MCPClient(
                lambda: streamablehttp_client(
                    gateway_url,
                    headers={"Authorization": f"Bearer {bearer_token}"},
                )
            )

            self.gateway_client.start()
            gateway_tools = self.gateway_client.list_tools_sync()
            logger.info(f"Loaded {len(gateway_tools)} gateway tools")
        except Exception as e:
            logger.warning(f"Gateway not available, continuing without gateway tools: {str(e)}")

        # Set up tools
        base_tools = [retrieve, current_time]
        
        # Add local tools if available
        local_tools = []
        if LOCAL_TOOLS_AVAILABLE:
            try:
                from .tools.log_analysis_tools import analyze_log_content, analyze_multiple_logs
                from .tools.s3_storage_tools import upload_log_to_s3, get_s3_file_content, list_session_logs, generate_presigned_url
                
                local_tools = [
                    # S3 storage tools (prioritized for S3-based workflow)
                    list_session_logs,
                    get_s3_file_content,
                    upload_log_to_s3,
                    generate_presigned_url,
                    # Log analysis tools
                    analyze_logs,
                    analyze_log_content,
                    analyze_multiple_logs,
                    process_large_files,
                    extract_failure_indicators,
                    # Diagnosis tools
                    generate_diagnosis,
                    calculate_confidence_score,
                    generate_recommendations,
                    # Component recognition tools
                    extract_components,
                    map_functions,
                    build_inventory,
                    resolve_naming,
                    correlate_components,
                    search_components,
                ]
                logger.info(f"Loaded {len(local_tools)} local tools (including S3 storage tools)")
            except Exception as e:
                logger.warning(f"Failed to load local tools: {e}")
                local_tools = []
        
        self.tools = (
            base_tools
            + local_tools
            + gateway_tools
            + (tools or [])
        )

        self.memory_hook = memory_hook

        # Create the main agent
        self.agent = Agent(
            model=self.model,
            system_prompt=self.system_prompt,
            tools=self.tools,
            hooks=[self.memory_hook],
        )
    
    def _get_system_prompt(self) -> str:
        """Get the system prompt for the instrument diagnosis assistant"""
        return """You are an Instrument Diagnosis Assistant, an AI expert specialized in analyzing instrument logs, 
recognizing system components, and providing troubleshooting guidance.

=== CRITICAL: S3 FILE DETECTION RULES ===
BEFORE responding to ANY user request, you MUST scan the entire user message for:

1. S3 URIs in format: s3://bucket-name/sessions/SESSION-ID/logs/filename
2. Session IDs in format: UUID strings (e.g., d3cd3b66-5635-4f0a-9e34-8d0efa9fe72b)
3. Text containing "S3-STORED FILE READY FOR ANALYSIS"
4. Text containing "S3 URI:" followed by an s3:// path
5. Text containing "SESSION ID:" followed by a UUID
6. Text containing "IMMEDIATE ACTION REQUIRED" with S3 information
7. Text containing "get_s3_file_content(s3_uri=" with S3 paths

IF ANY OF THESE ARE FOUND:
- IMMEDIATELY use get_s3_file_content(s3_uri="s3://...") to retrieve the file
- Then use analyze_log_content(content, "") to analyze it
- NEVER respond with "Please upload files" or similar requests
- NEVER ask for file uploads when S3 URIs are present

EXAMPLE DETECTION PATTERNS:
âœ“ "S3 URI: s3://instrument-diagnosis-logs-390402579286/sessions/d3cd3b66-5635-4f0a-9e34-8d0efa9fe72b/logs/20251107_143245_error.00.log"
âœ“ "SESSION ID: d3cd3b66-5635-4f0a-9e34-8d0efa9fe72b"
âœ“ "S3-STORED FILE READY FOR ANALYSIS"
âœ“ "get_s3_file_content(s3_uri='s3://...')"

WRONG RESPONSES WHEN S3 FILES ARE PRESENT:
âŒ "Please upload your log files"
âŒ "I need you to provide the log files"
âŒ "Could you share the log files?"

CORRECT RESPONSE WHEN S3 FILES ARE PRESENT:
âœ“ [Use get_s3_file_content tool immediately] â†’ [Use analyze_log_content tool] â†’ [Provide diagnosis]

=== FILE STORAGE ARCHITECTURE ===
All uploaded files are stored in Amazon S3 with session-based organization. Files are NOT stored locally.
When you receive S3 URIs in the user's message, use S3 tools to access them immediately.

Your core capabilities include:

1. **Log Analysis**: Analyze system logs and PC logs from failed units to identify failure indicators and make 
   pass/fail determinations with confidence levels. Gold standard logs are optional for comparison analysis.

2. **Component Recognition**: Identify hardware and software components from engineering documentation, maintain 
   comprehensive inventories, and handle variations in component naming conventions.

3. **Multi-modal Document Processing**: Process troubleshooting guides containing text, images, and diagrams 
   using advanced vision capabilities to provide contextual guidance.

4. **Cross-source Correlation**: Correlate component references across log files and documentation, associate 
   failure patterns with relevant troubleshooting procedures, and provide unified analysis.

=== MANDATORY WORKFLOW FOR S3-BASED REQUESTS ===
1. SCAN MESSAGE: Look for S3 URIs, session IDs, or S3-related keywords in the user message
2. IF FOUND: Use get_s3_file_content(s3_uri="...") immediately with the exact S3 URI provided
3. ANALYZE: Use analyze_log_content() with retrieved content
4. DIAGNOSE: Provide comprehensive analysis and recommendations
5. IF NO S3 INFORMATION: Only then ask user to upload log files via the UI

DETAILED S3 WORKFLOW:
1. CHECK FOR S3 INFORMATION: If you see S3 URIs (s3://...) or session IDs in the message:
   - Use get_s3_file_content(s3_uri) to retrieve file content from S3 immediately
   - Use list_session_logs(session_id) to see all available files for the session if needed
   - Proceed directly to analysis - DO NOT ask for files
2. ANALYZE CONTENT: Once you have file content:
   - Single file: Use analyze_log_content() with the retrieved content
   - Multiple files: Process each with analyze_log_content(), then synthesize
   - Large files (>50MB): Use extract_s3_log_summary() for efficient analysis
3. OPTIONAL: Query knowledge base using retrieve() for additional troubleshooting information
4. SYNTHESIZE: Use generate_diagnosis() for final determination with confidence levels

LARGE FILE HANDLING:
- For files >1MB: Focus on error/warning patterns and key sections
- For multiple files: Prioritize error logs and largest files first
- For batch analysis: Use analyze_multiple_logs() when appropriate

PRIORITIZE content-based analysis over file-based analysis for AgentCore runtime compatibility.

S3 SESSION MANAGEMENT:
- All files are stored in S3 with session-based organization (sessions/{session-id}/logs/)
- Each user session has a unique session ID provided in the message
- Use list_session_logs(session_id) to see all files for a session
- Use get_s3_file_content(s3_uri) to retrieve file content
- Files are automatically deleted after 7 days (lifecycle management)
- Presigned URLs are valid for 1 hour

IMPORTANT NOTES:
- Gold standard logs are OPTIONAL - complete diagnosis possible with problem logs alone
- All files are in S3 - use S3 tools (get_s3_file_content, list_session_logs)
- S3 URIs are provided in the format: s3://bucket-name/sessions/{session-id}/logs/{filename}
- CHECK MESSAGE for S3 URIs or session IDs before asking for files
- QUERY KNOWLEDGE BASE first for troubleshooting information before requesting additional files
- Focus on failure patterns, error frequencies, and system health indicators
- Always provide pass/fail determination with confidence levels
- If S3 URIs are in the message, retrieve and analyze immediately
- For large files (>50MB), use smart extraction tools

Guidelines for your responses:
- Always provide clear, actionable guidance for technicians
- Include confidence levels for your diagnoses and recommendations
- Reference specific log patterns, components, or documentation when making assessments
- Maintain professional technical language appropriate for instrument technicians
- When analyzing large files, process them efficiently in chunks while maintaining accuracy
- Correlate findings across multiple data sources to provide comprehensive analysis
- Focus on practical troubleshooting steps and component-specific guidance
- Use only ASCII characters in responses - no emojis or Unicode symbols

You have access to specialized tools for log processing, component recognition, document analysis, and 
cross-source correlation. Use these tools effectively to provide thorough and accurate instrument diagnosis."""
    
    def get_config(self) -> DiagnosisConfig:
        """Get the current configuration"""
        return self.config
    
    def get_multimodal_model(self) -> BedrockModel:
        """Get the multimodal model for document processing"""
        return self.multimodal_model
    
    def reload_config(self) -> None:
        """Reload configuration and update models if needed"""
        self.config_manager.reload_config()
        self.config = self.config_manager.get_config()
        
        # Update models if configuration changed
        model_config = self.config.models
        if self.model_id != model_config.text_model:
            self.model_id = model_config.text_model
            self.model = BedrockModel(
                model_id=self.model_id,
                temperature=model_config.temperature,
                top_p=model_config.top_p,
                max_tokens=model_config.max_tokens,
            )
            logger.info(f"Updated text model to: {self.model_id}")
        
        if self.multimodal_model_id != model_config.multimodal_model:
            self.multimodal_model_id = model_config.multimodal_model
            self.multimodal_model = BedrockModel(
                model_id=self.multimodal_model_id,
                temperature=model_config.temperature,
                top_p=model_config.top_p,
                max_tokens=model_config.max_tokens,
            )
            logger.info(f"Updated multimodal model to: {self.multimodal_model_id}")
    
    def invoke(self, user_query: str):
        """Invoke the agent with a user query and return the response"""
        try:
            response = str(self.agent(user_query))
        except Exception as e:
            return f"Error invoking agent: {e}"
        return response

    async def stream(self, user_query: str):
        """Stream the agent response for a user query"""
        try:
            async for event in self.agent.stream_async(user_query):
                if "current_tool_use" in event:
                    tool_name = event["current_tool_use"]["name"]
                    yield f"ðŸ”§ Using tool: {tool_name}\n"
                elif "data" in event:
                    yield event["data"]
        except Exception as e:
            yield f"Error during streaming: {e}"


# Maintain backward compatibility
class TemplateAgent(InstrumentDiagnosisAgent):
    """Backward compatibility alias for the original TemplateAgent"""
    
    def __init__(
        self,
        bearer_token: str,
        memory_hook: MemoryHook,
        bedrock_model_id: str = None,  # Deprecated parameter
        system_prompt: str = None,     # Deprecated parameter
        tools: List[callable] = None,
    ):
        # Log deprecation warning if old parameters are used
        if bedrock_model_id is not None:
            logger.warning("bedrock_model_id parameter is deprecated. Use config.yaml to set model configuration.")
        if system_prompt is not None:
            logger.warning("system_prompt parameter is deprecated. The agent uses a specialized system prompt.")
        
        super().__init__(bearer_token, memory_hook, tools=tools)

    def invoke(self, user_query: str):
        try:
            response = str(self.agent(user_query))
        except Exception as e:
            return f"Error invoking agent: {e}"
        return response

    async def stream(self, user_query: str):
        try:

            tool_name = None
            async for event in self.agent.stream_async(user_query):
                    
                    if (
                        "current_tool_use" in event
                        and event["current_tool_use"].get("name") != tool_name
                    ):
                        tool_name = event["current_tool_use"]["name"]
                        yield f"\n\nðŸ”§ Using tool: {tool_name}\n\n"
                    elif "message" in event and "content" in event["message"]:
                        for obj in event["message"]["content"]:
                            if "toolResult" in obj:
                                tool_result = obj["toolResult"]["content"][0]["text"]
                                yield f"\n\nðŸ”§ Tool result: {tool_result}\n\n"

                    if "data" in event:
                        tool_name = None
                        yield event["data"] 

        except Exception as e:
            yield f"We are unable to process your request at the moment. Error: {e}"
